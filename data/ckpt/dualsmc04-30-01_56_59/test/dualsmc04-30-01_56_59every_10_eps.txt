
Episode 10: mean/stdev steps taken = 107.8 / 96.1350901365134, reward = 50 / 52.69724850502159, avg_plan_time = 0.027816037593190925 / 0.0001357405949846028, avg_dist = 0.0676188526568113 / 0.058272791373464805
Episode 20: mean/stdev steps taken = 90.45 / 90.94733872441036, reward = 60 / 50.25932749251625, avg_plan_time = 0.02781659002299276 / 0.000146639745337806, avg_dist = 0.08037419664094456 / 0.05700480340208157
Episode 30: mean/stdev steps taken = 102.6 / 91.72620428058788, reward = 53 / 50.73460357586329, avg_plan_time = 0.027813778271539892 / 0.00013935542885150996, avg_dist = 0.07013101981613322 / 0.05336229955420679
Episode 40: mean/stdev steps taken = 104.15 / 91.3835394480389, reward = 52 / 50.566787519082126, avg_plan_time = 0.027816634376150878 / 0.00014115487595042143, avg_dist = 0.06998309278383578 / 0.05208141502135806
Episode 50: mean/stdev steps taken = 101.24 / 91.16022225976076, reward = 54 / 50.33885179461288, avg_plan_time = 0.027812891461502204 / 0.00013381635159346732, avg_dist = 0.07430420211827594 / 0.05436033292578656
Episode 60: mean/stdev steps taken = 96.36666666666666 / 90.528386159066, reward = 56 / 49.969990994595946, avg_plan_time = 0.027822246691845184 / 0.00014902337248486261, avg_dist = 0.07758561638859315 / 0.056863983502302366
Episode 70: mean/stdev steps taken = 92.87142857142857 / 89.92201475200632, reward = 58 / 49.60846701924985, avg_plan_time = 0.02781924366779529 / 0.0001477451121317003, avg_dist = 0.07766866363535996 / 0.05509152332769136
Episode 80: mean/stdev steps taken = 95 / 89.99774962024806, reward = 57 / 49.73932046178355, avg_plan_time = 0.027814703048803693 / 0.00014375113597242672, avg_dist = 0.07729803262571082 / 0.055606429507114606
Episode 90: mean/stdev steps taken = 94.42222222222222 / 89.92068637250759, reward = 57 / 49.658836071740545, avg_plan_time = 0.027821218490168182 / 0.00015088054552736514, avg_dist = 0.07822934600502669 / 0.05656062611442465
Episode 100: mean/stdev steps taken = 90.42 / 89.12358687448423, reward = 60 / 49.23413450036468, avg_plan_time = 0.027830079101625077 / 0.00015428643443290667, avg_dist = 0.07866045767417013 / 0.055078427327890984
Episode 110: mean/stdev steps taken = 92.03636363636363 / 89.42681157716281, reward = 59 / 49.38623289946298, avg_plan_time = 0.027828352104678555 / 0.00015151870448164545, avg_dist = 0.07895971765863732 / 0.056373268805673914
Episode 120: mean/stdev steps taken = 94.89166666666667 / 89.8993644487619, reward = 57 / 49.63869458396343, avg_plan_time = 0.027828547807619605 / 0.00014832691098123525, avg_dist = 0.07619421269516705 / 0.055621028479037576
Episode 130: mean/stdev steps taken = 95.96153846153847 / 90.00055157851253, reward = 56 / 49.70915408654627, avg_plan_time = 0.027827508214356773 / 0.0001479778715245083, avg_dist = 0.07574337566724092 / 0.055956738508920884
Episode 140: mean/stdev steps taken = 95.6 / 89.88800385707802, reward = 57 / 49.658836071740545, avg_plan_time = 0.027826905961084485 / 0.0001467394006816357, avg_dist = 0.07576985352477292 / 0.05551547036727756
Episode 150: mean/stdev steps taken = 95.24666666666667 / 89.82346120833459, reward = 57 / 49.61854492022111, avg_plan_time = 0.027824456863776794 / 0.00014431678693289872, avg_dist = 0.07526825813772933 / 0.0548205964313582
Episode 160: mean/stdev steps taken = 94.98125 / 89.72729276875606, reward = 57 / 49.58830507286975, avg_plan_time = 0.02782368162072057 / 0.00014155080338165547, avg_dist = 0.07554610796313908 / 0.055160898759941304
Episode 170: mean/stdev steps taken = 96.82941176470588 / 89.98632548781988, reward = 56 / 49.71921157862421, avg_plan_time = 0.02782069764400154 / 0.00013982071259888374, avg_dist = 0.07433433383031013 / 0.054858495517423826
Episode 180: mean/stdev steps taken = 97.44444444444444 / 90.08526204789061, reward = 56 / 49.759421218498915, avg_plan_time = 0.02782286068381548 / 0.0001414672129838672, avg_dist = 0.07417921423820649 / 0.05494820671365991
Episode 190: mean/stdev steps taken = 97.06315789473685 / 90.03465652857417, reward = 56 / 49.72926703662542, avg_plan_time = 0.027823168240362805 / 0.00014153494720722118, avg_dist = 0.07462820083359917 / 0.05535815621495503
Episode 200: mean/stdev steps taken = 99.45 / 90.28935896166581, reward = 55 / 49.86983055916673, avg_plan_time = 0.027821536781821376 / 0.00013907986024334467, avg_dist = 0.07348074053752472 / 0.05548215200111276
Episode 210: mean/stdev steps taken = 101.60952380952381 / 90.46519807071178, reward = 53 / 49.969990994595946, avg_plan_time = 0.02782410177126108 / 0.0001417656641654699, avg_dist = 0.07248674603765663 / 0.05553438346426213
Episode 220: mean/stdev steps taken = 100.23181818181818 / 90.38560663673215, reward = 54 / 49.8998997994986, avg_plan_time = 0.027826539292615752 / 0.00014383285624399198, avg_dist = 0.07246802688426997 / 0.05502416961095465
Episode 230: mean/stdev steps taken = 100.6 / 90.3989507996462, reward = 54 / 49.90991885387112, avg_plan_time = 0.02782731396516657 / 0.00014564757535404644, avg_dist = 0.07292763695794902 / 0.05542005463458161
Episode 240: mean/stdev steps taken = 100.94166666666666 / 90.40594602518414, reward = 54 / 49.92995093127971, avg_plan_time = 0.027825838222013847 / 0.00014444359134922283, avg_dist = 0.07308834923488922 / 0.05557561587780684
Episode 250: mean/stdev steps taken = 101.24 / 90.42602425990991, reward = 54 / 49.92995093127971, avg_plan_time = 0.027823390646935665 / 0.00014288422476841758, avg_dist = 0.07315335058984701 / 0.05559587172709354
Episode 260: mean/stdev steps taken = 100.79615384615384 / 90.40898484738418, reward = 54 / 49.90991885387112, avg_plan_time = 0.027823950786892974 / 0.00014366481173725017, avg_dist = 0.07358474172296008 / 0.05573478155916491
Episode 270: mean/stdev steps taken = 101.07037037037037 / 90.43512458235809, reward = 54 / 49.91993589739474, avg_plan_time = 0.027823390677839243 / 0.00014342142391935198, avg_dist = 0.07361824223723858 / 0.05594112110825768
Episode 280: mean/stdev steps taken = 100.69285714285714 / 90.39177147412487, reward = 54 / 49.8998997994986, avg_plan_time = 0.027824308836407168 / 0.00014336511964160222, avg_dist = 0.07395832406997858 / 0.05611899604601438
Episode 290: mean/stdev steps taken = 100.30689655172414 / 90.38184445420595, reward = 54 / 49.879855653359705, avg_plan_time = 0.02782325556799625 / 0.00014236633609631018, avg_dist = 0.07423564143138556 / 0.055969785616211125
Episode 300: mean/stdev steps taken = 101.18333333333334 / 90.44935974242681, reward = 54 / 49.91993589739474, avg_plan_time = 0.027822218736172577 / 0.0001413525117143791, avg_dist = 0.07386100099976921 / 0.05606576692976833
Episode 310: mean/stdev steps taken = 103.18709677419355 / 90.56580772433286, reward = 52 / 49.98999899979995, avg_plan_time = 0.02782217008787354 / 0.00014041304541422282, avg_dist = 0.07276686161935464 / 0.05587785134991666
Episode 320: mean/stdev steps taken = 102.834375 / 90.4916945196498, reward = 53 / 49.9799959983992, avg_plan_time = 0.027823235328234098 / 0.00014188587964018967, avg_dist = 0.07333788002276341 / 0.05618617414658486
Episode 330: mean/stdev steps taken = 102.47272727272727 / 90.44859922609011, reward = 53 / 49.95998398718719, avg_plan_time = 0.027823692270452536 / 0.000142362071855474, avg_dist = 0.07347897113640549 / 0.05604935273753394
Episode 340: mean/stdev steps taken = 101.59117647058824 / 90.37539170781196, reward = 53 / 49.91993589739474, avg_plan_time = 0.027825384057026427 / 0.00014349878864244493, avg_dist = 0.0739782462645924 / 0.05600086873072932
Episode 350: mean/stdev steps taken = 101.25428571428571 / 90.36275776101576, reward = 54 / 49.90991885387112, avg_plan_time = 0.02782465815996351 / 0.00014334214504194796, avg_dist = 0.07378396753172235 / 0.05560841701610102
Episode 360: mean/stdev steps taken = 100.93333333333334 / 90.352241680003, reward = 54 / 49.889878733065686, avg_plan_time = 0.027827426777956216 / 0.00015027753385610368, avg_dist = 0.07416659807464518 / 0.055905454918912766
Episode 370: mean/stdev steps taken = 101.13243243243244 / 90.36976901181507, reward = 54 / 49.8998997994986, avg_plan_time = 0.02782813494737664 / 0.00015123162451513247, avg_dist = 0.07370406411659558 / 0.05566234980108841
Episode 380: mean/stdev steps taken = 101.80526315789474 / 90.41548174389548, reward = 53 / 49.91993589739474, avg_plan_time = 0.02782734755636052 / 0.00015113878632873654, avg_dist = 0.07341559991739943 / 0.05559684699017406
Episode 390: mean/stdev steps taken = 101.97948717948718 / 90.42166056297093, reward = 53 / 49.92995093127971, avg_plan_time = 0.02782902798868175 / 0.00015223360864856486, avg_dist = 0.07342840123476214 / 0.05551833437325456
Episode 400: mean/stdev steps taken = 103.945 / 90.54597400503958, reward = 52 / 50.0, avg_plan_time = 0.02782872021167664 / 0.00015111978624869724, avg_dist = 0.07247210693839157 / 0.055723359017544626
Episode 410: mean/stdev steps taken = 104.06585365853658 / 90.53880041892992, reward = 52 / 50.0, avg_plan_time = 0.02782852942266139 / 0.00014992261976953987, avg_dist = 0.07225572743757307 / 0.05561732886155434
Episode 420: mean/stdev steps taken = 104.62857142857143 / 90.53548015781098, reward = 52 / 50.00999900019995, avg_plan_time = 0.02782958843974052 / 0.00015047336671954306, avg_dist = 0.07204910117672658 / 0.05566727501008652
Episode 430: mean/stdev steps taken = 103.03953488372093 / 90.44691327511008, reward = 53 / 49.95998398718719, avg_plan_time = 0.027830375560842467 / 0.00015151585369170767, avg_dist = 0.0731069029401191 / 0.05581104432037638
Episode 440: mean/stdev steps taken = 102.78863636363636 / 90.39298336888547, reward = 53 / 49.949974974968704, avg_plan_time = 0.02783069840043786 / 0.00015180977749009665, avg_dist = 0.07327628574470843 / 0.055731775878391114
Episode 450: mean/stdev steps taken = 102.52666666666667 / 90.36143928948734, reward = 53 / 49.93996395673509, avg_plan_time = 0.02783026850402964 / 0.0001515325342254753, avg_dist = 0.07345627593838247 / 0.0557179317227427
Episode 460: mean/stdev steps taken = 101.45 / 90.30934309904148, reward = 53 / 49.8998997994986, avg_plan_time = 0.02783019731432456 / 0.00015141378991028576, avg_dist = 0.07393311540723582 / 0.05570079153281739
Episode 470: mean/stdev steps taken = 101.60851063829787 / 90.31170809062442, reward = 53 / 49.8998997994986, avg_plan_time = 0.027829263760042012 / 0.00015053555862561181, avg_dist = 0.07391820740612118 / 0.05564223286259869
Episode 480: mean/stdev steps taken = 100.625 / 90.22588794769435, reward = 54 / 49.85980344927164, avg_plan_time = 0.027830048951666957 / 0.00015102098184757126, avg_dist = 0.07443533735377947 / 0.05562103421799483
Episode 490: mean/stdev steps taken = 100.78775510204082 / 90.23699682600879, reward = 54 / 49.85980344927164, avg_plan_time = 0.02783007116062736 / 0.0001514289325342628, avg_dist = 0.07429496688753212 / 0.05558514769206218
Episode 500: mean/stdev steps taken = 101.312 / 90.27137141416424, reward = 54 / 49.879855653359705, avg_plan_time = 0.027829880696221533 / 0.00015053693997250277, avg_dist = 0.07395549772757619 / 0.0555069568828034
Episode 510: mean/stdev steps taken = 101.08235294117647 / 90.26791101325213, reward = 54 / 49.86983055916673, avg_plan_time = 0.0278296531494485 / 0.0001516137623537173, avg_dist = 0.07411463645689273 / 0.055561210717987135
Episode 520: mean/stdev steps taken = 100.86538461538461 / 90.26013120428954, reward = 54 / 49.85980344927164, avg_plan_time = 0.027829319071764124 / 0.00015126534404375923, avg_dist = 0.07443821835525995 / 0.05579500946342854
Episode 530: mean/stdev steps taken = 101.00188679245284 / 90.27784248260585, reward = 54 / 49.86983055916673, avg_plan_time = 0.02782978191005316 / 0.00015183705548180282, avg_dist = 0.07418906649611134 / 0.055643235030953725
Episode 540: mean/stdev steps taken = 100.1462962962963 / 90.19024874984845, reward = 54 / 49.82971001320397, avg_plan_time = 0.027829236554254726 / 0.0001512541360227403, avg_dist = 0.07485259251681241 / 0.05580276517636408
Episode 550: mean/stdev steps taken = 100.28363636363636 / 90.21669675237186, reward = 54 / 49.82971001320397, avg_plan_time = 0.02783049293196845 / 0.00015313632984957813, avg_dist = 0.07488240763199494 / 0.05593739169140031
Episode 560: mean/stdev steps taken = 100.43571428571428 / 90.22374975119844, reward = 54 / 49.839743177508446, avg_plan_time = 0.02783113890227557 / 0.0001534894899913243, avg_dist = 0.07475180784904097 / 0.05592981196662311
Episode 570: mean/stdev steps taken = 100.2719298245614 / 90.19538302647247, reward = 54 / 49.82971001320397, avg_plan_time = 0.027839505809969984 / 0.00022602857469443985, avg_dist = 0.0750036323165996 / 0.056093578772665735
Episode 580: mean/stdev steps taken = 100.72931034482758 / 90.23146690350377, reward = 54 / 49.84977432245807, avg_plan_time = 0.0278379331955379 / 0.0002251339454670301, avg_dist = 0.07472318958068386 / 0.05603175758495174
Episode 590: mean/stdev steps taken = 101.78813559322033 / 90.3087189294836, reward = 53 / 49.8998997994986, avg_plan_time = 0.027835796069632723 / 0.0002240000023884713, avg_dist = 0.07413929914022671 / 0.056044089817795954
Episode 600: mean/stdev steps taken = 102.505 / 90.35668500933653, reward = 53 / 49.92995093127971, avg_plan_time = 0.02783452002847373 / 0.00022288183749275478, avg_dist = 0.07385752869939849 / 0.056129950296014225
Episode 610: mean/stdev steps taken = 102.28852459016393 / 90.35957380077855, reward = 53 / 49.91993589739474, avg_plan_time = 0.027833684038434416 / 0.00022210403317315927, avg_dist = 0.07366054660812442 / 0.055917682166874955
Episode 620: mean/stdev steps taken = 102.10967741935484 / 90.33334910830861, reward = 53 / 49.90991885387112, avg_plan_time = 0.02783322853183871 / 0.00022145708232821024, avg_dist = 0.07388465249986564 / 0.05605271013117449
Episode 630: mean/stdev steps taken = 102.20952380952382 / 90.3413623616004, reward = 53 / 49.90991885387112, avg_plan_time = 0.027838560572371426 / 0.00023494543508129434, avg_dist = 0.07390823585092562 / 0.056163978044859925
Episode 640: mean/stdev steps taken = 102.5953125 / 90.36197583031554, reward = 53 / 49.92995093127971, avg_plan_time = 0.02783698245514474 / 0.00023387187422129344, avg_dist = 0.07380730433186863 / 0.05624402977105584
Episode 650: mean/stdev steps taken = 102.69538461538461 / 90.35874133602277, reward = 53 / 49.92995093127971, avg_plan_time = 0.027835334683759372 / 0.00023269905295787423, avg_dist = 0.0737624565988392 / 0.05617407262882558
Episode 660: mean/stdev steps taken = 102.78939393939395 / 90.35833004451415, reward = 53 / 49.92995093127971, avg_plan_time = 0.027834424418258594 / 0.0002316594131321325, avg_dist = 0.07357898808107015 / 0.05605310492764614
Episode 670: mean/stdev steps taken = 102.86716417910448 / 90.37038201539418, reward = 53 / 49.92995093127971, avg_plan_time = 0.027833102149076028 / 0.00023081963074515164, avg_dist = 0.07370694683621104 / 0.05613310008001079
Episode 680: mean/stdev steps taken = 101.87058823529412 / 90.31724981304463, reward = 53 / 49.8998997994986, avg_plan_time = 0.027832310044792995 / 0.0002296130531498577, avg_dist = 0.07428131722920132 / 0.05619374407053416
Episode 690: mean/stdev steps taken = 102.75507246376812 / 90.37562002867828, reward = 53 / 49.92995093127971, avg_plan_time = 0.02783065546488152 / 0.00022868270592992407, avg_dist = 0.07372502917660051 / 0.056110618116515396
Episode 700: mean/stdev steps taken = 103.36285714285714 / 90.4031175026607, reward = 52 / 49.949974974968704, avg_plan_time = 0.02782886428967424 / 0.00022767267667388297, avg_dist = 0.07345231635737834 / 0.056141557563751006
Episode 710: mean/stdev steps taken = 103.69014084507042 / 90.42050199217044, reward = 52 / 49.95998398718719, avg_plan_time = 0.027828158501148746 / 0.0002268344085195604, avg_dist = 0.07319868123607357 / 0.05605117894113744
Episode 720: mean/stdev steps taken = 103.52222222222223 / 90.39440426978054, reward = 52 / 49.949974974968704, avg_plan_time = 0.02782725141867653 / 0.00022589081012968024, avg_dist = 0.07334512771610892 / 0.056108907610247706
Episode 730: mean/stdev steps taken = 103.84657534246575 / 90.40320302511074, reward = 52 / 49.95998398718719, avg_plan_time = 0.02782595752595057 / 0.00022504662179839653, avg_dist = 0.07315828890503558 / 0.05610893518428383
Episode 740: mean/stdev steps taken = 103.92702702702702 / 90.38971449458916, reward = 52 / 49.95998398718719, avg_plan_time = 0.02782495750711938 / 0.00022425833228915362, avg_dist = 0.07310818318938597 / 0.056080953162476715
Episode 750: mean/stdev steps taken = 104.45866666666667 / 90.42724741095086, reward = 52 / 49.9799959983992, avg_plan_time = 0.027823860827847952 / 0.00022333709879376624, avg_dist = 0.07275994938834006 / 0.05598528649268368
Episode 760: mean/stdev steps taken = 104.04473684210527 / 90.39856469696792, reward = 52 / 49.969990994595946, avg_plan_time = 0.02782298049684056 / 0.00022244806781903864, avg_dist = 0.07315554092666092 / 0.056188581580685834
Episode 770: mean/stdev steps taken = 103.62337662337663 / 90.38602935895567, reward = 52 / 49.949974974968704, avg_plan_time = 0.027822137875985843 / 0.00022149241653640975, avg_dist = 0.07333580888390703 / 0.05610264364609383
Episode 780: mean/stdev steps taken = 103.68333333333334 / 90.39170772723071, reward = 52 / 49.949974974968704, avg_plan_time = 0.02782089520046005 / 0.00022055763181463435, avg_dist = 0.07332700441473876 / 0.05611437865418661
Episode 790: mean/stdev steps taken = 104.20253164556962 / 90.41788349904587, reward = 52 / 49.969990994595946, avg_plan_time = 0.027822484245473105 / 0.00022674923444936213, avg_dist = 0.07302174659378388 / 0.05608550415699228
Episode 800: mean/stdev steps taken = 104.47875 / 90.43414713008816, reward = 52 / 49.9799959983992, avg_plan_time = 0.027826894779416293 / 0.00024122781713270324, avg_dist = 0.07292258920513374 / 0.05605563468187495
Episode 810: mean/stdev steps taken = 104.74074074074075 / 90.45645515278528, reward = 52 / 49.9799959983992, avg_plan_time = 0.027826005027066298 / 0.00023991146374315676, avg_dist = 0.07274854427661813 / 0.05601789929036353
Episode 820: mean/stdev steps taken = 105.45243902439024 / 90.4792904962009, reward = 51 / 50.0, avg_plan_time = 0.027824906088965345 / 0.00023879405481577878, avg_dist = 0.07236968727642788 / 0.05597656827508564
Episode 830: mean/stdev steps taken = 105.49036144578314 / 90.4791255633917, reward = 51 / 50.0, avg_plan_time = 0.027825918244413255 / 0.00023830537600165488, avg_dist = 0.07239254952603282 / 0.055934430708919305
Episode 840: mean/stdev steps taken = 105.31309523809524 / 90.4704869330475, reward = 51 / 49.98999899979995, avg_plan_time = 0.027825741346086303 / 0.00023715550305653834, avg_dist = 0.07261429882580246 / 0.05611097310478361
Episode 850: mean/stdev steps taken = 104.93529411764706 / 90.44570595538154, reward = 52 / 49.9799959983992, avg_plan_time = 0.02782625067206888 / 0.0002364968780137548, avg_dist = 0.07277933334736822 / 0.056070428290506305
Episode 860: mean/stdev steps taken = 104.97209302325581 / 90.45173997514641, reward = 51 / 49.9799959983992, avg_plan_time = 0.02782599836120829 / 0.00023585388662448347, avg_dist = 0.07264501288023158 / 0.05600027514693937
Episode 870: mean/stdev steps taken = 104.60114942528736 / 90.43185355153935, reward = 52 / 49.9799959983992, avg_plan_time = 0.02782573108309912 / 0.0002346456125073049, avg_dist = 0.07290687123659417 / 0.0560253547240537
Episode 880: mean/stdev steps taken = 104.44318181818181 / 90.42141987951307, reward = 52 / 49.969990994595946, avg_plan_time = 0.027825512142214435 / 0.000233855007016995, avg_dist = 0.07297430091492346 / 0.05599225427700876
Episode 890: mean/stdev steps taken = 104.28988764044944 / 90.40993510431618, reward = 52 / 49.969990994595946, avg_plan_time = 0.027825346581510875 / 0.00023273895648125454, avg_dist = 0.07313307226794387 / 0.055990217071517294
Episode 900: mean/stdev steps taken = 104.53888888888889 / 90.4202008624972, reward = 52 / 49.969990994595946, avg_plan_time = 0.027825324737051578 / 0.00023188778648783873, avg_dist = 0.07301745836505832 / 0.05591874294048433
Episode 910: mean/stdev steps taken = 104.5923076923077 / 90.41277878610973, reward = 52 / 49.969990994595946, avg_plan_time = 0.027825331631572692 / 0.00023123095900568828, avg_dist = 0.07298971184891181 / 0.0558671954756873
Episode 920: mean/stdev steps taken = 105.225 / 90.43807315599857, reward = 51 / 49.98999899979995, avg_plan_time = 0.027825191871765326 / 0.00023070190127547825, avg_dist = 0.0726304835257621 / 0.055838949495124926
Episode 930: mean/stdev steps taken = 105.2516129032258 / 90.44790543755892, reward = 51 / 49.98999899979995, avg_plan_time = 0.027825011405812585 / 0.00022989139968851595, avg_dist = 0.07257928451075657 / 0.055811095142987155
Episode 940: mean/stdev steps taken = 105.29148936170213 / 90.44404793067451, reward = 51 / 49.98999899979995, avg_plan_time = 0.027825066507458373 / 0.0002293322302405455, avg_dist = 0.07260940509572515 / 0.05588202461133003
Episode 950: mean/stdev steps taken = 104.9421052631579 / 90.43333108842478, reward = 52 / 49.9799959983992, avg_plan_time = 0.02782540798681473 / 0.00022871802426183962, avg_dist = 0.07286931225434341 / 0.05591464861165947
Episode 960: mean/stdev steps taken = 104.98125 / 90.43293889060598, reward = 51 / 49.9799959983992, avg_plan_time = 0.027824497208593348 / 0.00022792614756456098, avg_dist = 0.07278250454164252 / 0.05592640473225671
Episode 970: mean/stdev steps taken = 104.83711340206186 / 90.42115805759342, reward = 52 / 49.9799959983992, avg_plan_time = 0.02782384762147864 / 0.0002271110973855925, avg_dist = 0.07292612302722833 / 0.05594797329239769
Episode 980: mean/stdev steps taken = 104.87755102040816 / 90.41989951846871, reward = 52 / 49.9799959983992, avg_plan_time = 0.027823083051106565 / 0.00022637521426990153, avg_dist = 0.07285991760738608 / 0.05594841109318045
Episode 990: mean/stdev steps taken = 104.73838383838384 / 90.40734265019579, reward = 52 / 49.9799959983992, avg_plan_time = 0.027822790552473067 / 0.00022563917789784793, avg_dist = 0.0729241201775506 / 0.05596668965109232
Episode 1000: mean/stdev steps taken = 104.77 / 90.41494324480861, reward = 52 / 49.9799959983992, avg_plan_time = 0.027822234586505318 / 0.00022505588844438202, avg_dist = 0.0728671355811017 / 0.05596719064911962