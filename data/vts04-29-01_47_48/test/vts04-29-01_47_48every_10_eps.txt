
Episode 10: mean/stdev steps taken = 28.7 / 6.3095166217389425, reward = 100.0 / 0.0, avg_plan_time = 0.1937213239923575 / 0.00986572190154793, avg_dist = 0.08258894925906472 / 0.024377757131344276
Episode 20: mean/stdev steps taken = 29.6 / 6.514598989960933, reward = 100.0 / 0.0, avg_plan_time = 0.19626098312177132 / 0.007724360352947264, avg_dist = 0.08736238265870505 / 0.021404389371601062
Episode 30: mean/stdev steps taken = 30.1 / 7.2034713853808015, reward = 100.0 / 0.0, avg_plan_time = 0.1969594909930348 / 0.006931135809891068, avg_dist = 0.08817166425941313 / 0.021261170638620257
Episode 40: mean/stdev steps taken = 30.45 / 7.063816249025734, reward = 100.0 / 0.0, avg_plan_time = 0.19742308830202934 / 0.006236069424328159, avg_dist = 0.09094731942476161 / 0.02516097658363032
Episode 50: mean/stdev steps taken = 29.7 / 7.040596565632773, reward = 100.0 / 0.0, avg_plan_time = 0.19662985750426948 / 0.006053279663848534, avg_dist = 0.0844381853490161 / 0.027295833122301022
Episode 60: mean/stdev steps taken = 29.65 / 6.9060963406737, reward = 100.0 / 0.0, avg_plan_time = 0.19673862954629703 / 0.005940018985107498, avg_dist = 0.08468267055443676 / 0.029366927141802696
Episode 70: mean/stdev steps taken = 29.985714285714284 / 7.233834899065555, reward = 100.0 / 0.0, avg_plan_time = 0.1970758449168638 / 0.005733696423030795, avg_dist = 0.08681392572679103 / 0.03002587630390015
Episode 80: mean/stdev steps taken = 30.525 / 7.563026841152952, reward = 100.0 / 0.0, avg_plan_time = 0.19708722440641452 / 0.005458899202932415, avg_dist = 0.08673525573720371 / 0.030986351105725334
Episode 90: mean/stdev steps taken = 30.455555555555556 / 7.560366115636804, reward = 100.0 / 0.0, avg_plan_time = 0.19708762910299302 / 0.005338148578469309, avg_dist = 0.0876136738971049 / 0.03072336789463612
Episode 100: mean/stdev steps taken = 30.09 / 7.3581179658931815, reward = 100.0 / 0.0, avg_plan_time = 0.1966307611596066 / 0.005549115884933235, avg_dist = 0.0850872956859703 / 0.030835431658296823
Episode 110: mean/stdev steps taken = 29.945454545454545 / 7.3495038343802666, reward = 100.0 / 0.0, avg_plan_time = 0.19675506091443362 / 0.005541038813180984, avg_dist = 0.08455051194553802 / 0.031246930684555366
Episode 120: mean/stdev steps taken = 31.241666666666667 / 16.962702139956622, reward = 81.66666666666667 / 199.9930554349881, avg_plan_time = 0.19565567585137852 / 0.012154264636526375, avg_dist = 0.08796051861360024 / 0.04779031704111024
Episode 130: mean/stdev steps taken = 30.715384615384615 / 16.486000875047623, reward = 83.07692307692308 / 192.20920555016312, avg_plan_time = 0.1954764610250584 / 0.011738989502093783, avg_dist = 0.08556572271051782 / 0.047060930253508715
Episode 140: mean/stdev steps taken = 30.4 / 16.012851981187755, reward = 84.28571428571429 / 185.2686962115251, avg_plan_time = 0.1953661782186312 / 0.011416541774494266, avg_dist = 0.0852025171030722 / 0.04620313529961791
Episode 150: mean/stdev steps taken = 30.166666666666668 / 15.58264704371144, reward = 85.33333333333333 / 179.02948236409432, avg_plan_time = 0.19527907673012695 / 0.011111332779997072, avg_dist = 0.08400548769333585 / 0.04585349175510777
Episode 160: mean/stdev steps taken = 30.53125 / 15.36022537066107, reward = 86.25 / 173.38090292762925, avg_plan_time = 0.1951281902526964 / 0.011266469963262471, avg_dist = 0.08455892519911287 / 0.04497307612305463
Episode 170: mean/stdev steps taken = 30.764705882352942 / 15.19995902380199, reward = 87.05882352941177 / 168.2352941176471, avg_plan_time = 0.19520054042786147 / 0.010978816200604823, avg_dist = 0.08429344477347699 / 0.044711108862016194
Episode 180: mean/stdev steps taken = 30.75 / 14.91154474448126, reward = 87.77777777777777 / 163.52218862539576, avg_plan_time = 0.19511857216638545 / 0.010758566163640435, avg_dist = 0.08401945872075826 / 0.04540232830592336
Episode 190: mean/stdev steps taken = 30.83157894736842 / 14.609767916005946, reward = 88.42105263157895 / 159.18420835109754, avg_plan_time = 0.1952057255083683 / 0.010500494182144856, avg_dist = 0.08364105542109539 / 0.04466577046359351
Episode 200: mean/stdev steps taken = 30.745 / 14.388883730157804, reward = 89.0 / 155.17409577632472, avg_plan_time = 0.19521089767859168 / 0.01028567952065771, avg_dist = 0.0834927270753656 / 0.04406284453908481
Episode 210: mean/stdev steps taken = 30.733333333333334 / 14.158804541053104, reward = 89.52380952380952 / 151.45252880267668, avg_plan_time = 0.1952421889185276 / 0.010200576017195508, avg_dist = 0.08412146432533335 / 0.04432849229415515
Episode 220: mean/stdev steps taken = 30.831818181818182 / 14.031260111999154, reward = 90.0 / 147.9864858694874, avg_plan_time = 0.19525453773526674 / 0.010198970781025638, avg_dist = 0.08418705681879173 / 0.04400427162746259
Episode 230: mean/stdev steps taken = 30.969565217391306 / 14.023394577032269, reward = 90.43478260869566 / 144.7480047431627, avg_plan_time = 0.19532821062416544 / 0.010009464251648535, avg_dist = 0.08410429162458617 / 0.043415443768590425
Episode 240: mean/stdev steps taken = 31.1875 / 14.431817063349992, reward = 90.41666666666667 / 141.83262338247698, avg_plan_time = 0.19511097404429212 / 0.010033403249563711, avg_dist = 0.08417509656465298 / 0.04379072396773785
Episode 250: mean/stdev steps taken = 31.312 / 14.460382290935465, reward = 90.8 / 138.97971074944718, avg_plan_time = 0.19512630878456716 / 0.009878296785372545, avg_dist = 0.08388341022646693 / 0.04330404858316951
Episode 260: mean/stdev steps taken = 31.076923076923077 / 14.245979397503103, reward = 91.15384615384616 / 136.29230248248186, avg_plan_time = 0.19496884738414846 / 0.009791288797433037, avg_dist = 0.08318597309749431 / 0.04274149666085525
Episode 270: mean/stdev steps taken = 31.05185185185185 / 14.060619299631266, reward = 91.48148148148148 / 133.75499170203935, avg_plan_time = 0.1949433061143191 / 0.009777116771139923, avg_dist = 0.08337546741457616 / 0.04299310267374997
Episode 280: mean/stdev steps taken = 30.742857142857144 / 13.914982382090088, reward = 91.78571428571429 / 131.35430743463516, avg_plan_time = 0.19484529837595876 / 0.00965364381697414, avg_dist = 0.08246594510273157 / 0.04289035829385075
Episode 290: mean/stdev steps taken = 30.613793103448277 / 13.744057628485296, reward = 92.06896551724138 / 129.07841269192838, avg_plan_time = 0.19485620485317548 / 0.009553602487420577, avg_dist = 0.08230705744608176 / 0.04267427079378377
Episode 300: mean/stdev steps taken = 30.573333333333334 / 13.601395353255326, reward = 92.33333333333333 / 126.9168581745108, avg_plan_time = 0.19484151883328796 / 0.009455659240242295, avg_dist = 0.08225721684183275 / 0.04238103657610118
Episode 310: mean/stdev steps taken = 30.51290322580645 / 13.438443696746836, reward = 92.58064516129032 / 124.86037988128939, avg_plan_time = 0.19479139296422462 / 0.009472523339178028, avg_dist = 0.0826121512962376 / 0.042226644884956324
Episode 320: mean/stdev steps taken = 30.53125 / 13.263870982390472, reward = 92.8125 / 122.90073166482777, avg_plan_time = 0.19470934430883563 / 0.009496940999972782, avg_dist = 0.08201906357195843 / 0.04205353264758332
Episode 330: mean/stdev steps taken = 30.53939393939394 / 13.24889793916413, reward = 93.03030303030303 / 121.03054581848457, avg_plan_time = 0.19467947449284495 / 0.009458831276388028, avg_dist = 0.08158753483338858 / 0.041767996393327914
Episode 340: mean/stdev steps taken = 31.08823529411765 / 15.99019487623371, reward = 85.88235294117646 / 180.13259245636783, avg_plan_time = 0.19437863596138133 / 0.011317916389435807, avg_dist = 0.08266789015654694 / 0.04650997299696628
Episode 350: mean/stdev steps taken = 30.945714285714285 / 15.827820766109328, reward = 86.28571428571429 / 177.5561997837098, avg_plan_time = 0.19437690326478693 / 0.01117131907799539, avg_dist = 0.08219975454957577 / 0.04605013130212602
Episode 360: mean/stdev steps taken = 30.933333333333334 / 15.650736581885068, reward = 86.66666666666667 / 175.08727982225196, avg_plan_time = 0.19447306577221868 / 0.01104783363737729, avg_dist = 0.08251108321555585 / 0.04570004639211021
Episode 370: mean/stdev steps taken = 30.808108108108108 / 15.494670023057855, reward = 87.02702702702703 / 172.71856290579342, avg_plan_time = 0.19454288959248228 / 0.01093271510146816, avg_dist = 0.08239491308858798 / 0.0453679242789244
Episode 380: mean/stdev steps taken = 30.773684210526316 / 15.327523990839182, reward = 87.36842105263158 / 170.4434496514486, avg_plan_time = 0.19455615509869173 / 0.010847514787177494, avg_dist = 0.08241703626983674 / 0.04517087995678609
Episode 390: mean/stdev steps taken = 30.807692307692307 / 15.175095735183751, reward = 87.6923076923077 / 168.25593354053703, avg_plan_time = 0.19459684996911744 / 0.010730555639041732, avg_dist = 0.08232315513992748 / 0.04496292107181482
Episode 400: mean/stdev steps taken = 30.845 / 15.088935515800975, reward = 88.0 / 166.15053415502462, avg_plan_time = 0.19457093374063703 / 0.010645217307907512, avg_dist = 0.0820749043960026 / 0.04463686197505461
Episode 410: mean/stdev steps taken = 30.819512195121952 / 14.939115778714992, reward = 88.29268292682927 / 164.12223937862763, avg_plan_time = 0.1947008707106292 / 0.01055458291604351, avg_dist = 0.08252342049466835 / 0.0443373428446264
Episode 420: mean/stdev steps taken = 30.704761904761906 / 14.837965339611126, reward = 88.57142857142857 / 162.16645517391515, avg_plan_time = 0.194777993913588 / 0.010457649960195234, avg_dist = 0.08292811807850257 / 0.044431338656386946
Episode 430: mean/stdev steps taken = 31.095348837209304 / 16.788499018581657, reward = 82.09302325581395 / 212.25322896752127, avg_plan_time = 0.19451644583854244 / 0.01222060385586939, avg_dist = 0.08415476467079629 / 0.0478275538257387
Episode 440: mean/stdev steps taken = 31.34090909090909 / 17.96808177880759, reward = 81.5909090909091 / 210.63155230507675, avg_plan_time = 0.19449008163803405 / 0.012166775538646458, avg_dist = 0.08452776052550978 / 0.047740564309728103
Episode 450: mean/stdev steps taken = 31.733333333333334 / 19.458217344408048, reward = 74.66666666666667 / 259.36332303032617, avg_plan_time = 0.19429941798233535 / 0.013528445285676705, avg_dist = 0.08562836569271129 / 0.05064727640936346
Episode 460: mean/stdev steps taken = 32.21304347826087 / 20.8607766821065, reward = 71.30434782608695 / 269.5455813325067, avg_plan_time = 0.19415995297726682 / 0.013930780687237094, avg_dist = 0.08618528547037148 / 0.051662800969379453
Episode 470: mean/stdev steps taken = 32.5468085106383 / 22.141348159609294, reward = 70.2127659574468 / 269.05262762659464, avg_plan_time = 0.19416313978739314 / 0.01384372204196837, avg_dist = 0.08642947731986257 / 0.0514843027375349
Episode 480: mean/stdev steps taken = 32.3875 / 21.956867044655226, reward = 70.83333333333333 / 266.26923509026636, avg_plan_time = 0.1941130960619662 / 0.013899689160563406, avg_dist = 0.08626771260901861 / 0.051121900657294626
Episode 490: mean/stdev steps taken = 32.344897959183676 / 21.75019175354825, reward = 71.42857142857143 / 263.57046070283, avg_plan_time = 0.19422312756920973 / 0.013782345697637867, avg_dist = 0.08622800770398112 / 0.050989583102404895
Episode 500: mean/stdev steps taken = 32.3 / 21.565759898505778, reward = 72.0 / 260.95210288480143, avg_plan_time = 0.19426681235313328 / 0.013658190756704564, avg_dist = 0.08619016391204375 / 0.050667897149610806
Episode 510: mean/stdev steps taken = 32.227450980392156 / 21.376898639963734, reward = 72.54901960784314 / 258.4102463916927, avg_plan_time = 0.19430520002563792 / 0.013535800550940759, avg_dist = 0.0861716256459094 / 0.05046958220366067
Episode 520: mean/stdev steps taken = 32.103846153846156 / 21.19481033666262, reward = 73.07692307692308 / 255.9412377085086, avg_plan_time = 0.19431297944203194 / 0.0134765823758154, avg_dist = 0.08610523946775658 / 0.05024620472093306
Episode 530: mean/stdev steps taken = 32.03584905660377 / 21.01968165153633, reward = 73.58490566037736 / 253.54166297967788, avg_plan_time = 0.19431531988256306 / 0.013373038353794088, avg_dist = 0.08595016659265617 / 0.049921787495846234
Episode 540: mean/stdev steps taken = 32.22037037037037 / 21.731304264770003, reward = 70.92592592592592 / 261.3127012725652, avg_plan_time = 0.19429385971699692 / 0.01336830358909856, avg_dist = 0.08627968450380091 / 0.05041836365425688
Episode 550: mean/stdev steps taken = 32.18909090909091 / 21.554595989358344, reward = 71.45454545454545 / 258.9553712467086, avg_plan_time = 0.19428301882516674 / 0.01327710718074556, avg_dist = 0.08603792739032351 / 0.05010731404521739
Episode 560: mean/stdev steps taken = 32.11785714285714 / 21.384332608768716, reward = 71.96428571428571 / 256.66069627078485, avg_plan_time = 0.1943492567560065 / 0.013176216286812058, avg_dist = 0.08593490873167955 / 0.04975017044445453
Episode 570: mean/stdev steps taken = 32.12105263157895 / 21.2152149708738, reward = 72.45614035087719 / 254.4259496706357, avg_plan_time = 0.19440637242337908 / 0.013076431124750409, avg_dist = 0.08585462875585054 / 0.04946220545468435
Episode 580: mean/stdev steps taken = 32.012068965517244 / 21.066271273639153, reward = 72.93103448275862 / 252.24856802634903, avg_plan_time = 0.19438811651927876 / 0.01299984407272865, avg_dist = 0.08578839581939324 / 0.04928616814988553
Episode 590: mean/stdev steps taken = 31.947457627118645 / 20.91384146260033, reward = 73.38983050847457 / 250.12613881861736, avg_plan_time = 0.19436927743097127 / 0.012932891882695516, avg_dist = 0.08579989135041145 / 0.049631115304352116
Episode 600: mean/stdev steps taken = 32.16166666666667 / 21.8509846587186, reward = 69.66666666666667 / 267.79324528864095, avg_plan_time = 0.19419883133200674 / 0.013718555853192347, avg_dist = 0.08634391857763532 / 0.05161327248391187
Episode 610: mean/stdev steps taken = 32.10655737704918 / 21.698306716835198, reward = 70.1639344262295 / 265.61707803132185, avg_plan_time = 0.19418779522435864 / 0.01365951184908526, avg_dist = 0.08621017044765647 / 0.0512542788204414
Episode 620: mean/stdev steps taken = 32.19032258064516 / 21.74906530937423, reward = 69.83870967741936 / 264.16632062618015, avg_plan_time = 0.19416663689005867 / 0.013604204043922666, avg_dist = 0.08638689768831584 / 0.05112772051826416
Episode 630: mean/stdev steps taken = 32.15873015873016 / 21.609820187734865, reward = 70.31746031746032 / 262.08848774683526, avg_plan_time = 0.19418613844037388 / 0.01350735973640581, avg_dist = 0.08636198562570646 / 0.05102673115585912
Episode 640: mean/stdev steps taken = 32.0953125 / 21.458069065676526, reward = 70.78125 / 260.0589157257207, avg_plan_time = 0.19419906298868794 / 0.013421794255997616, avg_dist = 0.08632073018230826 / 0.050803608518027774
Episode 650: mean/stdev steps taken = 32.043076923076924 / 21.31553401940811, reward = 71.23076923076923 / 258.0757652157908, avg_plan_time = 0.19419873341546234 / 0.013327908926331768, avg_dist = 0.08624679040476282 / 0.050509885646641474
Episode 660: mean/stdev steps taken = 32.025757575757574 / 21.17368872263519, reward = 71.66666666666667 / 256.137293519146, avg_plan_time = 0.19419321340137297 / 0.013283899402422937, avg_dist = 0.08602007585668317 / 0.05026755415931498
Episode 670: mean/stdev steps taken = 32.211940298507464 / 22.00237112315879, reward = 68.80597014925372 / 267.71014838150404, avg_plan_time = 0.1939941534546594 / 0.014105852376592842, avg_dist = 0.086800824482025 / 0.05233853609025681
Episode 680: mean/stdev steps taken = 32.14705882352941 / 21.860362131628825, reward = 69.26470588235294 / 265.76092848134476, avg_plan_time = 0.194028994465743 / 0.014016672649375858, avg_dist = 0.08673834785015294 / 0.05205222008361023
Episode 690: mean/stdev steps taken = 32.155072463768114 / 21.725507857387726, reward = 69.71014492753623 / 263.8536650564989, avg_plan_time = 0.19408770503564413 / 0.013928437660002518, avg_dist = 0.0865788766860709 / 0.05182028796035888
Episode 700: mean/stdev steps taken = 32.177142857142854 / 21.583261844233245, reward = 70.14285714285714 / 261.9868745738603, avg_plan_time = 0.19413990968795702 / 0.013840014275942641, avg_dist = 0.08675432782446416 / 0.051612438984806525
Episode 710: mean/stdev steps taken = 32.138028169014085 / 21.46069034105612, reward = 70.56338028169014 / 260.15914589767453, avg_plan_time = 0.19413029453411065 / 0.013807603067951476, avg_dist = 0.08680041235968079 / 0.051380066040305435
Episode 720: mean/stdev steps taken = 32.3125 / 22.222320095270582, reward = 66.80555555555556 / 281.06111627232775, avg_plan_time = 0.19397446812590832 / 0.014424342243240816, avg_dist = 0.08718729888476484 / 0.05310278484518801
Episode 730: mean/stdev steps taken = 32.62602739726027 / 22.973388580019375, reward = 63.97260273972603 / 292.56185261505726, avg_plan_time = 0.193870869333913 / 0.015101895144348794, avg_dist = 0.08770330820903115 / 0.05462338684714974
Episode 740: mean/stdev steps taken = 32.554054054054056 / 22.841251144254688, reward = 64.45945945945945 / 290.60813167270874, avg_plan_time = 0.1938831727607496 / 0.015027088224568127, avg_dist = 0.08761017908597925 / 0.05436760372430926
Episode 750: mean/stdev steps taken = 32.552 / 22.70728141661466, reward = 64.93333333333334 / 288.6930242008321, avg_plan_time = 0.19386675162407468 / 0.014961377747578867, avg_dist = 0.08744197325070346 / 0.05405961206523559
Episode 760: mean/stdev steps taken = 32.51315789473684 / 22.569479520298522, reward = 65.39473684210526 / 286.815275181714, avg_plan_time = 0.1939039004071834 / 0.014872599941917837, avg_dist = 0.08736564054508678 / 0.05376195192937423
Episode 770: mean/stdev steps taken = 32.47792207792208 / 22.43791216169068, reward = 65.84415584415585 / 284.97368595473, avg_plan_time = 0.19395166605249792 / 0.014790056733296603, avg_dist = 0.08757301142692771 / 0.05357825287818707
Episode 780: mean/stdev steps taken = 32.55641025641026 / 22.339011465765157, reward = 66.28205128205128 / 283.16711100473265, avg_plan_time = 0.19403396204463882 / 0.014720202390389974, avg_dist = 0.08759053045955807 / 0.053392275688468334
Episode 790: mean/stdev steps taken = 32.51392405063291 / 22.224782234283428, reward = 66.70886075949367 / 281.3944549712655, avg_plan_time = 0.1940465287763794 / 0.014631808330213611, avg_dist = 0.08735565297665306 / 0.05314263932620671
Episode 800: mean/stdev steps taken = 32.45 / 22.10791713391382, reward = 67.125 / 279.654669860884, avg_plan_time = 0.1940556920959044 / 0.014567206331058288, avg_dist = 0.08717575083928895 / 0.052907223979634314
Episode 810: mean/stdev steps taken = 32.446913580246914 / 22.006907369176034, reward = 67.53086419753086 / 277.94675244648835, avg_plan_time = 0.1940773578506473 / 0.014489711053732144, avg_dist = 0.08705521122607604 / 0.05274890152883684
Episode 820: mean/stdev steps taken = 32.426829268292686 / 21.890208573923527, reward = 67.92682926829268 / 276.2697418390225, avg_plan_time = 0.19402341651292643 / 0.014469348461394391, avg_dist = 0.08694970851072613 / 0.052566607956518074
Episode 830: mean/stdev steps taken = 32.39277108433735 / 21.767389022370416, reward = 68.3132530120482 / 274.6227172182037, avg_plan_time = 0.19403861810044207 / 0.014419280546070863, avg_dist = 0.08702478644216104 / 0.05235974492511815
Episode 840: mean/stdev steps taken = 32.5452380952381 / 22.404513813716758, reward = 65.23809523809524 / 290.3711753964808, avg_plan_time = 0.1939525785158826 / 0.014620468874487601, avg_dist = 0.08736734074556646 / 0.05307975177116298
Episode 850: mean/stdev steps taken = 32.550588235294114 / 22.417386233375474, reward = 65.05882352941177 / 289.12087246121393, avg_plan_time = 0.1939367845716116 / 0.014577138300731868, avg_dist = 0.08744413169107057 / 0.05305978322619502
Episode 860: mean/stdev steps taken = 32.48255813953488 / 22.309314416516518, reward = 65.46511627906976 / 287.4594287925352, avg_plan_time = 0.19392693917572262 / 0.014504352709596298, avg_dist = 0.0873095745146549 / 0.05283358468323593
Episode 870: mean/stdev steps taken = 32.49885057471264 / 22.20716201264432, reward = 65.86206896551724 / 285.82629450455073, avg_plan_time = 0.19391947325366907 / 0.014449340751756797, avg_dist = 0.0873500127817985 / 0.052646273425959886
Episode 880: mean/stdev steps taken = 32.4625 / 22.09279917910317, reward = 66.25 / 284.22067490851987, avg_plan_time = 0.19394761345198042 / 0.014377242544138063, avg_dist = 0.08734889639769415 / 0.05249049661137029
Episode 890: mean/stdev steps taken = 32.423595505617975 / 21.98981645038852, reward = 66.62921348314607 / 282.64180619159396, avg_plan_time = 0.19394437400918965 / 0.014325949186254025, avg_dist = 0.08714300157681458 / 0.05228467053386158
Episode 900: mean/stdev steps taken = 32.46 / 22.01185438197639, reward = 66.77777777777777 / 281.14182967865474, avg_plan_time = 0.19396667120787658 / 0.01429606882996204, avg_dist = 0.08757275060768939 / 0.05244058467246838
Episode 910: mean/stdev steps taken = 32.425274725274726 / 21.92535835990464, reward = 67.14285714285714 / 279.61427793838, avg_plan_time = 0.19396378607557047 / 0.014246629229979019, avg_dist = 0.08761341790053974 / 0.05233004879996119
Episode 920: mean/stdev steps taken = 32.427173913043475 / 21.84707523585385, reward = 67.5 / 278.111351643624, avg_plan_time = 0.1939785095130007 / 0.014184227291294224, avg_dist = 0.087635233020434 / 0.05220724858313755
Episode 930: mean/stdev steps taken = 32.40860215053763 / 21.74329042926066, reward = 67.84946236559139 / 276.6323963579912, avg_plan_time = 0.19399421780544712 / 0.01411329217743961, avg_dist = 0.08754283719809798 / 0.051985065865697615
Episode 940: mean/stdev steps taken = 32.32021276595745 / 21.64787385652277, reward = 68.19148936170212 / 275.17678173160755, avg_plan_time = 0.19400902415386062 / 0.014046980649460578, avg_dist = 0.08746901962279476 / 0.05180043462940472
Episode 950: mean/stdev steps taken = 32.27789473684211 / 21.552008962152673, reward = 68.52631578947368 / 273.7439003734874, avg_plan_time = 0.1940205902162915 / 0.013981955414931406, avg_dist = 0.0872511710136584 / 0.051615944254269075
Episode 960: mean/stdev steps taken = 32.442708333333336 / 22.126267594534113, reward = 67.08333333333333 / 277.6010201510233, avg_plan_time = 0.1940015474845388 / 0.01401302790312136, avg_dist = 0.08731701060870588 / 0.051621998020740696
Episode 970: mean/stdev steps taken = 32.457731958762885 / 22.057814544620122, reward = 67.42268041237114 / 276.1863943681015, avg_plan_time = 0.19404439354955882 / 0.013950368329925704, avg_dist = 0.08728794729174379 / 0.05149532317779026
Episode 980: mean/stdev steps taken = 32.49591836734694 / 22.04945701755139, reward = 67.44897959183673 / 274.92414992729266, avg_plan_time = 0.19402483200764406 / 0.013902639022683188, avg_dist = 0.08744088810368923 / 0.05151724329977174
Episode 990: mean/stdev steps taken = 32.448484848484846 / 21.94770811824574, reward = 67.77777777777777 / 273.5514855813227, avg_plan_time = 0.19404896557842677 / 0.013843756484455435, avg_dist = 0.08743975624241096 / 0.051342554905803944